{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafc1d8-42af-48a4-bfa6-8dc071c6e371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51709e4a-6fc6-49c2-b26b-9b8d29255cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "\n",
    "import torch\n",
    "\n",
    "from dataset import SoccerNetClips, SoccerNetClipsTesting #,SoccerNetClipsOld\n",
    "from model import Model\n",
    "from train import trainer, test, testSpotting\n",
    "from loss import NLLLoss\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    logging.info(\"Parameters:\")\n",
    "    for arg in vars(args):\n",
    "        logging.info(arg.rjust(15) + \" : \" + str(getattr(args, arg)))\n",
    "\n",
    "    print('window size', args.window_size)\n",
    "    # create dataset\n",
    "    if not args.test_only:\n",
    "        dataset_Train = SoccerNetClips(path=args.SoccerNet_path, features=args.features, split=args.split_train, version=args.version, framerate=args.framerate, window_size=args.window_size)\n",
    "        dataset_Valid = SoccerNetClips(path=args.SoccerNet_path, features=args.features, split=args.split_valid, version=args.version, framerate=args.framerate, window_size=args.window_size)\n",
    "        dataset_Valid_metric  = SoccerNetClips(path=args.SoccerNet_path, features=args.features, split=args.split_valid, version=args.version, framerate=args.framerate, window_size=args.window_size)\n",
    "    dataset_Test  = SoccerNetClipsTesting(path=args.SoccerNet_path, features=args.features, split=args.split_test, version=args.version, framerate=args.framerate, window_size=args.window_size)\n",
    "\n",
    "    if args.feature_dim is None:\n",
    "        args.feature_dim = dataset_Test[0][1].shape[-1]\n",
    "        print(\"feature_dim found:\", args.feature_dim)\n",
    "    # create model\n",
    "    model = Model(weights=args.load_weights, input_size=args.feature_dim,\n",
    "                  num_classes=dataset_Test.num_classes, window_size=args.window_size, \n",
    "                  vocab_size = args.vocab_size,\n",
    "                  framerate=args.framerate, pool=args.pool).cuda()\n",
    "    logging.info(model)\n",
    "    total_params = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "    parameters_per_layer  = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "    logging.info(\"Total number of parameters: \" + str(total_params))\n",
    "\n",
    "    # create dataloader\n",
    "    if not args.test_only:\n",
    "        train_loader = torch.utils.data.DataLoader(dataset_Train,\n",
    "            batch_size=args.batch_size, shuffle=True,\n",
    "            num_workers=args.max_num_worker, pin_memory=True)\n",
    "\n",
    "        val_loader = torch.utils.data.DataLoader(dataset_Valid,\n",
    "            batch_size=args.batch_size, shuffle=False,\n",
    "            num_workers=args.max_num_worker, pin_memory=True)\n",
    "\n",
    "        val_metric_loader = torch.utils.data.DataLoader(dataset_Valid_metric,\n",
    "            batch_size=args.batch_size, shuffle=False,\n",
    "            num_workers=args.max_num_worker, pin_memory=True)\n",
    "\n",
    "\n",
    "    # training parameters\n",
    "    if not args.test_only:\n",
    "        criterion = NLLLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.LR, \n",
    "                                    betas=(0.9, 0.999), eps=1e-08, \n",
    "                                    weight_decay=0, amsgrad=False)\n",
    "\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True, patience=args.patience)\n",
    "\n",
    "        # start training\n",
    "        trainer(train_loader, val_loader, val_metric_loader, \n",
    "                model, optimizer, scheduler, criterion,\n",
    "                model_name=args.model_name,\n",
    "                max_epochs=args.max_epochs, evaluation_frequency=args.evaluation_frequency)\n",
    "\n",
    "    # For the best model only\n",
    "    checkpoint = torch.load(os.path.join(\"models\", args.model_name, \"model.pth.tar\"))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    # test on multiple splits [test/challenge]\n",
    "    for split in args.split_test:\n",
    "        dataset_Test  = SoccerNetClipsTesting(path=args.SoccerNet_path, features=args.features, split=[split], version=args.version, framerate=args.framerate, window_size=args.window_size)\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(dataset_Test,\n",
    "            batch_size=1, shuffle=False,\n",
    "            num_workers=1, pin_memory=True)\n",
    "\n",
    "        results = testSpotting(test_loader, model=model, model_name=args.model_name, NMS_window=args.NMS_window, NMS_threshold=args.NMS_threshold)\n",
    "        if results is None:\n",
    "            continue\n",
    "\n",
    "        a_mAP = results[\"a_mAP\"]\n",
    "        a_mAP_per_class = results[\"a_mAP_per_class\"]\n",
    "        a_mAP_visible = results[\"a_mAP_visible\"]\n",
    "        a_mAP_per_class_visible = results[\"a_mAP_per_class_visible\"]\n",
    "        a_mAP_unshown = results[\"a_mAP_unshown\"]\n",
    "        a_mAP_per_class_unshown = results[\"a_mAP_per_class_unshown\"]\n",
    "\n",
    "        logging.info(\"Best Performance at end of training \")\n",
    "        logging.info(\"a_mAP visibility all: \" +  str(a_mAP))\n",
    "        logging.info(\"a_mAP visibility all per class: \" +  str( a_mAP_per_class))\n",
    "        logging.info(\"a_mAP visibility visible: \" +  str( a_mAP_visible))\n",
    "        logging.info(\"a_mAP visibility visible per class: \" +  str( a_mAP_per_class_visible))\n",
    "        logging.info(\"a_mAP visibility unshown: \" +  str( a_mAP_unshown))\n",
    "        logging.info(\"a_mAP visibility unshown per class: \" +  str( a_mAP_per_class_unshown))\n",
    "\n",
    "    return a_mAP,a_mAP_visible,a_mAP_unshown\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    parser = ArgumentParser(description='context aware loss function', formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "    \n",
    "    parser.add_argument('--SoccerNet_path',   required=False, type=str,   default=\"/path/to/SoccerNet/\",     help='Path for SoccerNet' )\n",
    "    parser.add_argument('--features',   required=False, type=str,   default=\"ResNET_TF2.npy\",     help='Video features' )\n",
    "    parser.add_argument('--max_epochs',   required=False, type=int,   default=1000,     help='Maximum number of epochs' )\n",
    "    parser.add_argument('--load_weights',   required=False, type=str,   default=None,     help='weights to load' )\n",
    "    parser.add_argument('--model_name',   required=False, type=str,   default=\"NetVLAD++\",     help='named of the model to save' )\n",
    "    parser.add_argument('--test_only',   required=False, action='store_true',  help='Perform testing only' )\n",
    "\n",
    "    parser.add_argument('--split_train', nargs='+', default=[\"train\"], help='list of split for training')\n",
    "    parser.add_argument('--split_valid', nargs='+', default=[\"valid\"], help='list of split for validation')\n",
    "    parser.add_argument('--split_test', nargs='+', default=[\"test\", \"challenge\"], help='list of split for testing')\n",
    "\n",
    "    parser.add_argument('--version', required=False, type=int,   default=2,     help='Version of the dataset' )\n",
    "    parser.add_argument('--feature_dim', required=False, type=int,   default=None,     help='Number of input features' )\n",
    "    parser.add_argument('--evaluation_frequency', required=False, type=int,   default=10,     help='Number of chunks per epoch' )\n",
    "    parser.add_argument('--framerate', required=False, type=float,   default=2,     help='Framerate of the input features' )\n",
    "    parser.add_argument('--window_size', required=False, type=int,   default=15,     help='Size of the chunk (in seconds)' )\n",
    "    parser.add_argument('--pool',       required=False, type=str,   default=\"NetVLAD++\", help='How to pool' )\n",
    "    parser.add_argument('--vocab_size',       required=False, type=int,   default=64, help='Size of the vocabulary for NetVLAD' )\n",
    "    parser.add_argument('--NMS_window',       required=False, type=int,   default=30, help='NMS window in second' )\n",
    "    parser.add_argument('--NMS_threshold',       required=False, type=float,   default=0.0, help='NMS threshold for positive results' )\n",
    "\n",
    "    parser.add_argument('--batch_size', required=False, type=int,   default=256,     help='Batch size' )\n",
    "    parser.add_argument('--LR',       required=False, type=float,   default=1e-03, help='Learning Rate' )\n",
    "    parser.add_argument('--LRe',       required=False, type=float,   default=1e-06, help='Learning Rate end' )\n",
    "    parser.add_argument('--patience', required=False, type=int,   default=10,     help='Patience before reducing LR (ReduceLROnPlateau)' )\n",
    "\n",
    "    parser.add_argument('--GPU',        required=False, type=int,   default=-1,     help='ID of the GPU to use' )\n",
    "    parser.add_argument('--max_num_worker',   required=False, type=int,   default=4, help='number of worker to load data')\n",
    "    parser.add_argument('--seed',   required=False, type=int,   default=0, help='seed for reproducibility')\n",
    "\n",
    "    # parser.add_argument('--logging_dir',       required=False, type=str,   default=\"log\", help='Where to log' )\n",
    "    parser.add_argument('--loglevel',   required=False, type=str,   default='INFO', help='logging level')\n",
    "    \n",
    "    \n",
    "    parser.add_argument('--window_start', required=False, type=int,   default=15,     help='Size of the chunk (in seconds)' )\n",
    "    parser.add_argument('--window_end', required=False, type=int,   default=15,     help='Size of the chunk (in seconds)' )\n",
    "    parser.add_argument('--window_gap', required=False, type=int,   default=15,     help='Size of the chunk (in seconds)' )\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # for reproducibility\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    numeric_level = getattr(logging, args.loglevel.upper(), None)\n",
    "    if not isinstance(numeric_level, int):\n",
    "        raise ValueError('Invalid log level: %s' % args.loglevel)\n",
    "\n",
    "    os.makedirs(os.path.join(\"models\", args.model_name), exist_ok=True)\n",
    "    log_path = os.path.join(\"models\", args.model_name,\n",
    "                            datetime.now().strftime('%Y-%m-%d_%H-%M-%S.log'))\n",
    "    logging.basicConfig(\n",
    "        level=numeric_level,\n",
    "        format=\n",
    "        \"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path),\n",
    "            logging.StreamHandler()\n",
    "        ])\n",
    "\n",
    "    if args.GPU >= 0:\n",
    "        os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.GPU)\n",
    "\n",
    "\n",
    "    start=time.time()\n",
    "    logging.info('Starting main function')\n",
    "    \n",
    "    args.window_size=args.window_start\n",
    "    \n",
    "    seek_result=[]\n",
    "    while args.window_size<=args.window_end:\n",
    "        a_mAP,a_mAP_visible,a_mAP_unshown=main(args)\n",
    "        seek_result.append([args.window_size,a_mAP,a_mAP_visible,a_mAP_unshown])\n",
    "        \n",
    "        args.window_size+=window_gap\n",
    "        \n",
    "    \n",
    "    seek_result.sort(key=lambda x:x[1])\n",
    "    print('seek_result\\n window_size,a_mAP,a_mAP_visible,a_mAP_unshown\\n')\n",
    "    print(seek_result)\n",
    "    \n",
    "    logging.info(f'Total Execution Time is {time.time()-start} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692fb605-ab91-459b-9c97-81cddfa573b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fde1aa-54ed-443b-b71b-146105ecf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a6417f-e6cd-4f94-b9cc-0e2cf666e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "    parser = ArgumentParser(description='context aware loss function', formatter_class=ArgumentDefaultsHelpFormatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c14db07-ee97-41ab-aac9-6bdc3a613017",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--window_start', required=False, type=int,   default=15,     help='Size of the chunk (in seconds)' )\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce77816f-cd9e-436f-87a2-f503ab8eea16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.window_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018a099c-bccd-41a1-bb3c-c2ff81d1faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.window_start=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5ffd3c-bb39-4d95-a8ad-599d6a6e1ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.window_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1c74ed7-ca73-40f4-ac61-9996a571bdfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0b023b1b075e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for i in range(1,5,0.5):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soccer",
   "language": "python",
   "name": "soccer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
