from torch.utils.data import Dataset

import numpy as np
import random
import os
import time


from tqdm import tqdm

import torch

import logging
import json

from SoccerNet.Downloader import getListGames
from SoccerNet.Downloader import SoccerNetDownloader
from SoccerNet.Evaluation.utils import AverageMeter, EVENT_DICTIONARY_V2, INVERSE_EVENT_DICTIONARY_V2
from SoccerNet.Evaluation.utils import EVENT_DICTIONARY_V1, INVERSE_EVENT_DICTIONARY_V1



def get_length(video_fn):
    import cv2

    cap = cv2.VideoCapture(video_fn)
    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    return length 

def feats2clip(feats, stride, clip_length, padding = "replicate_last", off=0):
    if padding =="zeropad":
        print("beforepadding", feats.shape)
        pad = feats.shape[0] - int(feats.shape[0]/stride)*stride
        print("pad need to be", clip_length-pad)
        m = torch.nn.ZeroPad2d((0, 0, clip_length-pad, 0))
        feats = m(feats)
        print("afterpadding", feats.shape)
        # nn.ZeroPad2d(2)

    idx = torch.arange(start=0, end=feats.shape[0]-1, step=stride)
    # print('idx', idx, 'clip_length', clip_length)
    idxs = []
    for i in torch.arange(-off, clip_length-off):
        idxs.append(idx+i)
    idx = torch.stack(idxs, dim=1)
    # print('idx.shape', idx.shape)

    # print('idx0, idx1', idx[0], idx[1])
    if padding=="replicate_last":
        idx = idx.clamp(0, feats.shape[0]-1)
    # print(idx)
    return feats[idx,...]


class SoccerNetClips(Dataset):
    def __init__(self, path, features="ResNET_PCA512.npy", split=["train"], version=1, 
                framerate=2, window_size=15, spread=False):
        self.path = path
        self.listGames = getListGames(split)
        self.features = features
        self.window_size_frame = int(window_size*framerate)
        self.version = version
        if version == 1:
            self.num_classes = 3
            self.labels="Labels.json"
        elif version == 2:
            self.dict_event = EVENT_DICTIONARY_V2
            self.num_classes = 17
            self.labels="Labels-v2.json"

        logging.info("Pre-compute clips")
        self.game_feats = list()
        self.game_labels = list()

        # game_counter = 0
        for game in tqdm(self.listGames):
            # Load features
            feat_half1 = np.load(os.path.join(self.path, game, "1_" + self.features))
            t = np.load('/youtu_pedestrian_detection/junweil/action_datasets/soccernet/england_epl/2014-2015/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/1_mvit.npy')
            # print(t.shape)
            # print(os.path.join(self.path, game, "1_" + self.features), feat_half1.shape)
            # print(feat_half1.shape)
            feat_half1 = feat_half1.reshape(-1, feat_half1.shape[-1])
            feat_half2 = np.load(os.path.join(self.path, game, "2_" + self.features))
            feat_half2 = feat_half2.reshape(-1, feat_half2.shape[-1])
            feat_half1 = feats2clip(torch.from_numpy(feat_half1), stride=self.window_size_frame, clip_length=self.window_size_frame)
            feat_half2 = feats2clip(torch.from_numpy(feat_half2), stride=self.window_size_frame, clip_length=self.window_size_frame)

            print(feat_half1.shape)
            # Load labels
            labels = json.load(open(os.path.join(self.path, game, self.labels)))

            label_half1 = np.zeros((feat_half1.shape[0], self.num_classes+1))
            label_half1[:,0]=1 # those are BG classes
            label_half2 = np.zeros((feat_half2.shape[0], self.num_classes+1))
            label_half2[:,0]=1 # those are BG classes

            # assert False 
            for annotation in labels["annotations"]:

                time = annotation["gameTime"]
                event = annotation["label"]

                half = int(time[0])

                minutes = int(time[-5:-3])
                seconds = int(time[-2::])
                frame = int( framerate * ( seconds + 60 * minutes )  )

                if version == 1:
                    if "card" in event: label = 0
                    elif "subs" in event: label = 1
                    elif "soccer" in event: label = 2
                    else: continue
                elif version == 2:
                    if event not in self.dict_event:
                        continue
                    label = self.dict_event[event]

                # if label outside temporal of view
                if half == 1 and frame//self.window_size_frame>=label_half1.shape[0]:
                    continue
                if half == 2 and frame//self.window_size_frame>=label_half2.shape[0]:
                    continue

                label_idx = frame//self.window_size_frame
                def tmp_set(la_arr, idx, la):
                    if 0 <= idx < len(la_arr):
                        la_arr[idx][la] = 1 

                if half == 1:
                    label_half1[label_idx][0] = 0 # not BG anymore
                    label_half1[label_idx][label+1] = 1 # that's my class
                    if spread:
                        tmp_set(label_half1, label_idx-1, label+1)
                        tmp_set(label_half1, label_idx+1, label+1)
                if half == 2:
                    label_half2[label_idx][0] = 0 # not BG anymore
                    label_half2[label_idx][label+1] = 1 # that's my class
                    if spread:
                        tmp_set(label_half2, label_idx-1, label+1)
                        tmp_set(label_half2, label_idx+1, label+1)
                

            # print(label_half1.shape, label_half2.shape)
            # print(feat_half1.shape, feat_half2.shape)
            self.game_feats.append(feat_half1)
            self.game_feats.append(feat_half2)
            self.game_labels.append(label_half1)
            self.game_labels.append(label_half2)

        self.game_feats = np.concatenate(self.game_feats)
        self.game_labels = np.concatenate(self.game_labels)



    def __getitem__(self, index):
        """
        Args:
            index (int): Index
        Returns:
            clip_feat (np.array): clip of features.
            clip_labels (np.array): clip of labels for the segmentation.
            clip_targets (np.array): clip of targets for the spotting.
        """
        return self.game_feats[index,:,:], self.game_labels[index,:]

    def __len__(self):
        return len(self.game_feats)


class SoccerNetClipsTesting(Dataset):
    def __init__(self, path, features="ResNET_PCA512.npy", split=["test"], version=1, 
                framerate=2, window_size=15):
        self.path = path
        self.listGames = getListGames(split)
        self.features = features
        self.window_size_frame = int(window_size*framerate)
        self.framerate = framerate
        self.version = version
        self.split=split

        self.feat_list=os.listdir(path) 

        if version == 1:
            self.dict_event = EVENT_DICTIONARY_V1
            self.num_classes = 3
            self.labels="Labels.json"
        elif version == 2:
            self.dict_event = EVENT_DICTIONARY_V2
            self.num_classes = 17
            self.labels="Labels-v2.json"

        # logging.info("Checking/Download features and labels locally")
        # downloader = SoccerNetDownloader(path)
        # for s in split:
        #     if s == "challenge":
        #         downloader.downloadGames(files=[f"1_{self.features}", f"2_{self.features}"], split=[s], verbose=False,randomized=True)
        #     else:
        #         downloader.downloadGames(files=[self.labels, f"1_{self.features}", f"2_{self.features}"], split=[s], verbose=False,randomized=True)


    def __getitem__(self, index):
        """
        Args:
            index (int): Index
        Returns:
            feat_half1 (np.array): features for the 1st half.
            feat_half2 (np.array): features for the 2nd half.
            label_half1 (np.array): labels (one-hot) for the 1st half.
            label_half2 (np.array): labels (one-hot) for the 2nd half.
        """
        # Load features
        feat=np.load(os.path.join(self.path,self.feat_list[index]))
        feat = feat.reshape(-1, feat.shape[-1])

        # feat_half1 = np.load(os.path.join(self.path, self.listGames[index], "1_" + self.features))
        # feat_half1 = feat_half1.reshape(-1, feat_half1.shape[-1])
        # feat_half2 = np.load(os.path.join(self.path, self.listGames[index], "2_" + self.features))
        # feat_half2 = feat_half2.reshape(-1, feat_half2.shape[-1])

        # Load labels
        label_half1 = np.zeros((feat.shape[0], self.num_classes))
        label_half2 = np.zeros((feat.shape[0], self.num_classes))

        # check if annoation exists
        if os.path.exists(os.path.join(self.path, self.listGames[index], self.labels)):
            labels = json.load(open(os.path.join(self.path, self.listGames[index], self.labels)))

            for annotation in labels["annotations"]:

                time = annotation["gameTime"]
                event = annotation["label"]

                half = int(time[0])

                minutes = int(time[-5:-3])
                seconds = int(time[-2::])
                frame = int( self.framerate * ( seconds + 60 * minutes )  )

                if self.version == 1:
                    if "card" in event: label = 0
                    elif "subs" in event: label = 1
                    elif "soccer" in event: label = 2
                    else: continue
                elif self.version == 2:
                    if event not in self.dict_event:
                        continue
                    label = self.dict_event[event]

                value = 1
                if "visibility" in annotation.keys():
                    if annotation["visibility"] == "not shown":
                        value = -1

                if half == 1:
                    frame = min(frame, feat_half1.shape[0]-1)
                    label_half1[frame][label] = value

                if half == 2:
                    frame = min(frame, feat_half2.shape[0]-1)
                    label_half2[frame][label] = value


        feat = feats2clip(torch.from_numpy(feat), 
                        stride=1, off=int(self.window_size_frame/2), 
                        clip_length=self.window_size_frame)      
            

        # feat_half1 = feats2clip(torch.from_numpy(feat_half1), 
        #                 stride=1, off=int(self.window_size_frame/2), 
        #                 clip_length=self.window_size_frame)

        # feat_half2 = feats2clip(torch.from_numpy(feat_half2), 
        #                 stride=1, off=int(self.window_size_frame/2), 
        #                 clip_length=self.window_size_frame)

        
        return self.feat_list[index], feat, feat, label_half1, label_half2

    def __len__(self):
        return len(self.feat_list)

